{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22efb04e-cb43-4bca-9ac9-bc40915e4f8e",
   "metadata": {},
   "source": [
    "### Data Exploration and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a7ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f375f8-145d-4d1c-96b3-007d74ef19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import data_utils\n",
    "import img_utils\n",
    "from data_utils import get_transform, BloodCellDataset\n",
    "from bcnet import get_bcnet\n",
    "from train_eval_utils import (\n",
    "    hocv_model, \n",
    "    kfcv_model, \n",
    "    plot_metrics_per_epoch, \n",
    "    train_model, \n",
    "    eval_model, \n",
    "    save_model,\n",
    "    load_model,\n",
    "    model_predict\n",
    ")\n",
    "\n",
    "DATA_PATH = \"/storage/data\"  # Change this to the relative path where your data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9cb5ac",
   "metadata": {},
   "source": [
    "Plotting sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67012ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = data_utils.BloodCellDataset(DATA_PATH)\n",
    "image, target = full_dataset[0]\n",
    "img_utils.plot_img_w_box(image, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008f50a-d7cb-4185-9293-72aa7e2ff62d",
   "metadata": {},
   "source": [
    "The following preprocessing steps are performed here:\n",
    "\n",
    "1. Reading in 'annotations.csv' and checking for duplicates, followed by dropping them.\n",
    "2. Changing the class labels from 'rbc' and 'wbc' to 1 and 2 respectively. (0 is reserved for the background class)\n",
    "3. Saving the new preprocessed data as a new .csv file called \"clean_anno.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b017e5-322c-42fe-b5f4-39f1f705f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = pd.read_csv('{0}/annotations.csv'.format(DATA_PATH))\n",
    "dup_df = data_utils.get_duplicates(anno_df)\n",
    "to_drop=[dup_df.loc[(dup_df['image']=='image-1.png') & (dup_df['label']=='rbc'),:].index[0]]\n",
    "to_drop.append(dup_df.loc[(dup_df['image']=='image-100.png') & (dup_df['label']=='wbc'),:].index[0])\n",
    "to_drop.append(dup_df.loc[(dup_df['image']=='image-104.png') & (dup_df['label']=='wbc'),:].index[0])\n",
    "to_drop.append(dup_df.loc[(dup_df['image']=='image-114.png') & (dup_df['label']=='wbc'),:].index[0])\n",
    "clean_anno_df = anno_df.drop(to_drop)\n",
    "clean_anno_df['label'] = np.where(clean_anno_df['label']=='rbc', 1, 2)\n",
    "#clean_anno_df.to_csv('{0}/clean_anno.csv'.format(DATA_PATH), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ffc88b-4156-4328-94f7-61485ee57c71",
   "metadata": {},
   "source": [
    "Visualizing the distribution of RBCs to WBCs across all the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72571912-cfed-4ba3-ad2c-7a06ff693f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.get_class_distribution('{0}/clean_anno.csv'.format(DATA_PATH), ['image','label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aea283",
   "metadata": {},
   "source": [
    "### Cross Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80296376-7dcd-4c77-92e8-2e960d88452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 train-test split\n",
    "train_indices, test_indices = train_test_split(range(100), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf2b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold-out cross validation (uncomment and run only if you wish to do this, otherwise use 5-fold CV in the next cell)\n",
    "\n",
    "# frcnn = get_bcnet('retina', 3)\n",
    "# hocv_model(\n",
    "#     model=frcnn, \n",
    "#     dir_name='/storage/data', \n",
    "#     train_idxs=train_indices, \n",
    "#     val_idxs=test_indices, \n",
    "#     train_transforms=get_transform(True), \n",
    "#     val_transforms=get_transform(False), \n",
    "#     num_epochs=20, \n",
    "#     batch_size=2, \n",
    "#     learning_rate=0.01\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b5060-1313-4bce-be1e-0c809a751e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning here\n",
    "\n",
    "model_to_tune = 'frcnn'  # Adjust to which model you wish to tune for. One of ('frcnn', 'retina', 'ssd')\n",
    "\n",
    "train_hist, val_hist = kfcv_model(\n",
    "    model_type=model_to_tune,\n",
    "    dir_name=DATA_PATH,\n",
    "    train_idxs=train_indices,\n",
    "    train_transforms=get_transform(True),\n",
    "    val_transforms=get_transform(False),\n",
    "    num_epochs=30,   # Change this hyperparameter accordingly\n",
    "    batch_size=2,   # Change this hyperparameter accordingly\n",
    "    learning_rate=0.1,   # Change this hyperparameter accordingly\n",
    "    k_folds=5\n",
    ")\n",
    "\n",
    "plot_metrics_per_epoch(train_hist, val_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c1be5",
   "metadata": {},
   "source": [
    "From our the validation scores of each model, we will use these hyperparameters for the final training of the three models:\n",
    "\n",
    "* Faster R-CNN\n",
    "    * Number of epochs: 15\n",
    "    * Initial learning rate: 0.01\n",
    "    * Batch size: 2\n",
    "\n",
    "* RetinaNet\n",
    "    * Number of epochs: 15\n",
    "    * Initial learning rate: 0.05\n",
    "    * Batch size: 2\n",
    "\n",
    "* SSD\n",
    "    * Number of epochs: 15\n",
    "    * Initial learning rate: 0.005\n",
    "    * Batch size: 2\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddfd84f",
   "metadata": {},
   "source": [
    "### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adb561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all three models\n",
    "\n",
    "frcnn = get_bcnet(model_name='frcnn', num_classes=3, num_trainable_layers=1)\n",
    "retinanet = get_bcnet(model_name='retina', num_classes=3, num_trainable_layers=1)\n",
    "ssd_net = get_bcnet(model_name='ssd', num_classes=3, num_trainable_layers=1)\n",
    "\n",
    "frcnn = train_model(\n",
    "    model=frcnn,\n",
    "    dir_name=DATA_PATH,\n",
    "    train_idxs=train_indices,\n",
    "    transforms=get_transform(train=True),\n",
    "    num_epochs=15,\n",
    "    batch_size=2,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "retinanet = train_model(\n",
    "    model=retinanet,\n",
    "    dir_name=DATA_PATH,\n",
    "    train_idxs=train_indices,\n",
    "    transforms=get_transform(train=True),\n",
    "    num_epochs=15,\n",
    "    batch_size=2,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "\n",
    "ssd_net = train_model(\n",
    "    model=ssd_net,\n",
    "    dir_name=DATA_PATH,\n",
    "    train_idxs=train_indices,\n",
    "    transforms=get_transform(train=True),\n",
    "    num_epochs=15,\n",
    "    batch_size=2,\n",
    "    learning_rate=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6355a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on test set\n",
    "\n",
    "frcnn_test = eval_model(\n",
    "    model=frcnn,\n",
    "    dir_name=DATA_PATH,\n",
    "    test_idxs=test_indices,\n",
    "    test_transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "retina_test = eval_model(\n",
    "    model=retinanet,\n",
    "    dir_name=DATA_PATH,\n",
    "    test_idxs=test_indices,\n",
    "    test_transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "ssd_test = eval_model(\n",
    "    model=ssd_net,\n",
    "    dir_name=DATA_PATH,\n",
    "    test_idxs=test_indices,\n",
    "    test_transforms=get_transform(train=False)\n",
    ")\n",
    "\n",
    "for res in zip(['Faster R-CNN', 'RetinaNet', 'SSD'], [frcnn_test, retina_test, ssd_test]):\n",
    "    print(\n",
    "        '{0} --> COCO-mAP: {1:.4f}, mAP-50: {2:.4f}, mAP-75: {3:.4f}'.format(\n",
    "            res[0], res[1]['coco_map'], res[1]['map_50'], res[1]['map_75']\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1705e",
   "metadata": {},
   "source": [
    "### Generate predictions from final models\n",
    "\n",
    "Take note that we use non-maximum suppression here to remove \"excess\" bounding boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BloodCellDataset(DATA_PATH, get_transform(train=False))\n",
    "image, actual = test_dataset[0]\n",
    "predicted = model_predict(frcnn_test, image)\n",
    "# Plot the predicted bounding boxes\n",
    "img_utils.plot_img_w_box(image, predicted, nms=True, iou_threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3526c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual bounding boxes\n",
    "img_utils.plot_img_w_box(image, actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770845f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving models\n",
    "\n",
    "save_model(model=frcnn, save_path=\"saved_models/best_frcnn.pth\")\n",
    "save_model(model=retinanet, save_path=\"saved_models/best_retina.pth\")\n",
    "save_model(model=ssd_net, save_path=\"saved_models/best_ssd.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ab2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example on how to load a model from saved path\n",
    "new_frcnn = get_bcnet('frcnn', 3, 1)\n",
    "load_model(new_frcnn, \"saved_models/best_frcnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bcd_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1af91074378ab68225538e9ce9f99ca45d51a32dcb54e233cb8e1bb90701db83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
